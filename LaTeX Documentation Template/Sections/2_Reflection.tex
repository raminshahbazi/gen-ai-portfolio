\section{Reflection}
\label{sec:reflection}

\textbf{In 3-5 pages, 1500-2000 words}\\

This section needs to be adjusted to align with the reflection requirements specified in the selected task.\\

\textbf{Note:} You should address all the questions from your selected task. Please list each question and provide your answers in the following enumeration.\\

For example:
\begin{enumerate}
    \item What was the most interesting thing you learned while working on the portfolio? What aspects did you find interesting or surprising? 
    
     \textbf{Answer:} 
     The most interesting aspect of working on this portfolio was exploring the concept of multi-agent collaboration and leveraging different models to understand human-like interactions. It was my first time engaging with these advanced AI concepts, and I found the way multiple models could work together to be fascinating. The idea of integrating different agents, each specializing in distinct tasks, provided a fresh perspective on AI-based automation and optimization.
     
     Another surprising aspect was understanding the computational limitations of certain models in different environments. Initially, I expected that smaller, open-source models would provide a seamless experience, but I quickly realized that their efficiency and usability vary significantly depending on the task and the hardware environment. This experience reinforced the importance of model selection based on the context and use case.

     \item Which part of the portfolio are you (most) proud of? Why? What were the challenges you faced, and how did you overcome them? 
    
     \textbf{Answer:}
     I am particularly proud of my ability to navigate and use different language models effectively. At first, it was really frustrating because many models didn’t work well on my Windows computer, especially when I needed to process complex tasks. Even though there are plenty of free and open-source models, they still require a lot of computing power, which made things slow and difficult to manage.

To deal with this, I had to find different ways to make things work. I started by tweaking my prompts to get better results with less processing power. I also realized that trying to do everything at once wasn’t the best idea, so I broke tasks into smaller steps. For example, instead of making a model process an entire PDF file at once, I first extracted the important parts and only fed those into the model. This made things much more efficient and saved a lot of time.

Even though it was frustrating at times, this experience actually helped me understand AI tools in a deeper way. Instead of just using them, I learned how to work around their limitations and make them fit my needs. Now, I feel much more confident in using these tools and even customizing them for specific tasks in the future. I’m excited to see what else I can do with them as I keep learning and experimenting.

     \item What adjustments to your design and implementation were necessary during the implementation phase? What would you change or do differently if you had to do the portfolio task a second time? What would be potential areas for future improvement. 
    
     \textbf{Answer: }


One of the most significant adjustments I made was shifting my reliance from smaller, limited models to more powerful options such as OpenAI's GPT models and DeepSeek. Initially, I was disappointed with the performance of some open-source alternatives like LLaMA, but I soon realized that understanding their constraints was an essential part of the learning process.

If I were to repeat the portfolio task, I would invest more time in optimizing workflows for computational efficiency. I would also explore hybrid approaches that combine the strengths of different models—using smaller models for preprocessing and larger models for final inference. Future improvements could include fine-tuning models for specific tasks to improve accuracy and efficiency.


     \item Include a brief section on ethical considerations when using these models in research domain.
    
     \textbf{Answer: }


     When working with AI models in a research setting, ethical considerations must be a top priority. Two primary concerns stand out:
- **Data Privacy and Security:** AI models often process large volumes of data, some of which may contain sensitive information. Ensuring that personal or confidential data is anonymized before processing is crucial to preventing data breaches and privacy violations.
- **Plagiarism and Content Authenticity:** Generative AI models can inadvertently produce content that closely resembles existing material. Ensuring that generated content is properly cited and adheres to ethical research guidelines is essential to maintaining academic integrity.

While these two considerations are, in my view, the most critical, other ethical issues should also be acknowledged. Bias in AI models is a well-known challenge, as models may inherit biases present in their training data, potentially leading to unfair or inaccurate outputs. Transparency is another essential factor—users should have a clear understanding of how AI systems generate responses and what limitations they might have. Finally, responsible usage is key; AI should complement human decision-making rather than replace it in areas that require critical thinking and ethical judgment.


     \item From the lecture/course including guest lectures, what topic excited you the most? Why? What would you like to learn more about and why? 
    
     \textbf{Answer:}

     Several topics from the course were particularly exciting, including Retrieval-Augmented Generation (RAG), fine-tuning AI models, multi-agent collaboration, and some of the guest lectures that covered advanced AI topics.

One of the most interesting lectures was about mechanistic interpretability of large language models. It explained how we can actually understand what’s going on inside these models instead of just treating them as black boxes. This made me think more about how AI makes decisions and how we can improve trust in these systems.

Another guest lecture that stood out was about the evolution of scaling laws in large language models, hosted by Amazon Web Services. It showed how increasing model size and training data affects performance. It was really interesting to see how researchers figure out the best ways to scale AI models while balancing cost and efficiency.

There was also a lecture on using transformer models for anomaly detection in structured data. This was a different perspective on AI because it focused on spotting unusual patterns in large datasets. It made me realize how AI is useful beyond text generation and can help in real-world applications like fraud detection and cybersecurity.

Among all these, RAG was still my favorite because it allows AI to pull in outside knowledge rather than just depending on what it was trained on. I’d love to learn more about how it can be used in real-time applications, especially for research and business intelligence. Overall, the guest lectures gave me a better understanding of how AI is evolving and how it can be applied to different areas.



     \item  How did you find working with DIFY platform during the course work? Would you recommend using DIFY in learning Generative AI technologies and why? What is the best start for learning Generative AI either by Python code or No-code platforms and why? 
    
     \textbf{Answer: }


     DIFY was a well-designed platform, but I found it harder to use compared to just coding in Python. One big problem with no-code platforms like DIFY is that they don’t have enough documentation, and since not many people use them, it’s hard to find help when something goes wrong. If you run into an issue, there aren’t always clear solutions online, unlike coding, where there are tons of resources, forums, and examples to guide you.

     Another big issue is control. When coding, you can tweak things exactly how you want, but with platforms like DIFY, you're stuck with whatever options they provide. Sometimes, you want to do something specific, but the platform just doesn’t support it, so you either have to find a workaround or give up on that feature. They also tend to be slower, especially when handling more complex tasks, because you don’t get to optimize the code for your needs.
     
     Despite these problems, no-code platforms do have their benefits. They make it easier for beginners to get started without needing to write a lot of code. They are also good for quick experiments when you just want to test an idea without setting up an entire coding environment. For businesses or non-technical users, they can be useful for simple AI applications without needing a developer.
     
     But for someone who really wants to learn Generative AI properly, I think Python is the better choice. It gives more flexibility, better performance, and a deeper understanding of how AI models actually work. With coding, you have full control over the models, data, and customization, which is really important when working on real projects.


     \item How did you find the assignments and exercise in the course and how they help you in portfolio exam? 
    
     \textbf{Answer: }


The assignments and exercises in the course really helped me understand AI concepts in a hands-on way. One of the exercises involved fine-tuning the Mistral 7B model using LoRA, which was a cool experience because it showed how you can improve a model without needing massive computing power. It was interesting to see how the model changed before and after fine-tuning.

Another exercise was about building a RAG system using LangChain, which I found really useful. I liked learning how to make AI retrieve and use external information instead of just relying on what it was already trained on. It felt like giving the model a way to think beyond its pre-trained knowledge.

The most exciting one for me was creating a multi-agent system with AutoGen. It was fun to see how different AI agents could work together, either cooperating or competing, to solve tasks. This made me think about how AI could be used in real-world decision-making.

Even though some exercises were tricky, they helped me learn a lot. They prepared me well for the portfolio exam because I got to practice working with different AI tools and techniques. Overall, the exercises gave me a solid foundation for understanding and applying Generative AI in practical ways.

    
\end{enumerate}




 

 

