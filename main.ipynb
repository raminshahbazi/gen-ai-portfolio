{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install Requirements ()"
      ],
      "metadata": {
        "id": "N9QpaHdWScCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogen-agentchat autogen-ext[openai] -q\n",
        "!pip install groq -q\n",
        "!pip install arxiv -q\n",
        "!pip install PyPDF2 -q"
      ],
      "metadata": {
        "id": "Bv3056-vSioY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc999f15-77b6-4e37-9ced-cccf0ac39f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.9/161.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-sdk 1.16.0 requires opentelemetry-api==1.16.0, but you have opentelemetry-api 1.30.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
        "from autogen_agentchat.conditions import TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat, SelectorGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_core.tools import FunctionTool\n",
        "from autogen_agentchat.conditions import MaxMessageTermination\n",
        "import arxiv"
      ],
      "metadata": {
        "id": "b5rD4jrbjD52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "tokenGROQ = getpass('Enter GROQ_API_KEY here: ')\n",
        "os.environ[\"GROQ_API_KEY\"] = tokenGROQ"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i8fNwjgR_1Q",
        "outputId": "1a30b94f-c32f-4bca-d5e0-f367a9bc3d96"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter GROQ_API_KEY here: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent, UserProxyAgent\n",
        "from autogen_agentchat.conditions import TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "\n",
        "# Create the agents.\n",
        "custom_model_client = OpenAIChatCompletionClient(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "assistant = AssistantAgent(\"assistant\", model_client=custom_model_client)\n",
        "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)  # Use input() to get user input from console.\n",
        "\n",
        "# Create the termination condition which will end the conversation when the user says \"APPROVE\".\n",
        "termination = TextMentionTermination(\"DONE\")\n",
        "\n",
        "# Create the team.\n",
        "team = RoundRobinGroupChat([assistant, user_proxy], termination_condition=termination)\n",
        "\n",
        "# Run the conversation and stream to the console.\n",
        "stream = team.run_stream(task=\"the pdf file is a little bit large, can you read it if i sent it to you completely, or you need it in small chunks?\")\n",
        "await Console(stream)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_wawy2QRzD7",
        "outputId": "059970c4-f95c-4488-8d31-9c950743a607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "the pdf file is a little bit large, can you read it if i sent it to you completely, or you need it in small chunks?\n",
            "---------- assistant ----------\n",
            "I'm a large language model, I don't have the capability to directly receive or store files, including PDFs. I can process text-based input, but I don't have a file upload or download mechanism.\n",
            "\n",
            "If you'd like to share the content of the PDF with me, you can try copying and pasting the text into this chat window. If the text is too long, you can break it up into smaller chunks and send them to me one at a time. I'll do my best to assist you with the content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import arxiv\n",
        "\n",
        "# Construct the default API client.\n",
        "client = arxiv.Client()\n",
        "papers_ids = []\n",
        "\n",
        "# Search for the 10 most recent articles matching the keyword \"quantum.\"\n",
        "search = arxiv.Search(\n",
        "  query = \"Multi-agent LLM systems\",\n",
        "  max_results = 1,\n",
        "  sort_by = arxiv.SortCriterion.SubmittedDate\n",
        ")\n",
        "\n",
        "for result in client.results(search):\n",
        "  result.download_pdf(filename=f\"{result.get_short_id()}.pdf\")\n",
        "  papers_ids.append(result.get_short_id())\n",
        "  print(f\"\\nTitle: {result.get_short_id()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3--wxChSczw",
        "outputId": "5da3f36b-33cc-45be-aa19-1e617117c958"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Title: 2502.14867v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paper = next(arxiv.Client().results(arxiv.Search(id_list=[\"1605.08386v1\"])))\n",
        "print(paper.get_short_id())"
      ],
      "metadata": {
        "id": "Ep87-jkLTrUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9578c4b8-dc9a-44ae-c191-0693e9d8cd4a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1605.08386v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import openai\n",
        "\n",
        "# Step 1: Extract text from the PDF\n",
        "pdf_path = \"/content/2502.14867v1.pdf\"  # Adjust the path as needed\n",
        "paper_text = \"\"\n",
        "with open(pdf_path, \"rb\") as f:\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    for page in reader.pages:\n",
        "        page_text = page.extract_text()\n",
        "        if page_text:\n",
        "            paper_text += page_text + \"\\n\"\n",
        "\n",
        "# Step 2: Split the text into manageable chunks\n",
        "def chunk_text(text, max_length=2500):\n",
        "    \"\"\"Splits text into chunks of approximately max_length characters.\"\"\"\n",
        "    return [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
        "\n",
        "\n",
        "chunks = chunk_text(paper_text, max_length=2500)\n"
      ],
      "metadata": {
        "id": "5AunGDZrjK2O"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunks))"
      ],
      "metadata": {
        "id": "x0vdjyOajg2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae9597e-48d9-4fb6-9af9-c9b4da303dfd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count(texts):\n",
        "  total_words = 0\n",
        "  total_characters = 0\n",
        "\n",
        "  for doc in texts:\n",
        "      content = doc\n",
        "      word_count = len(content.split())  # Count words\n",
        "      char_count = len(content)         # Count characters\n",
        "      total_words += word_count\n",
        "      total_characters += char_count\n",
        "\n",
        "  num_docs = len(texts)\n",
        "  avg_words = total_words / num_docs if num_docs > 0 else 0\n",
        "  avg_characters = total_characters / num_docs if num_docs > 0 else 0\n",
        "\n",
        "  print(f\"Average words per document: {avg_words}\")\n",
        "  print(f\"Average characters per document: {avg_characters}\")\n",
        "\n",
        "word_count(chunks)"
      ],
      "metadata": {
        "id": "7mL6iI2R8VNC",
        "outputId": "0ca53fb7-9818-4852-e824-c4ba789f6839",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average words per document: 395.6666666666667\n",
            "Average characters per document: 2465.8888888888887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "\n",
        "# Convert text into Document objects\n",
        "documents = [Document(page_content=text) for text in chunks]\n",
        "\n",
        "# Initialize text splitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "\n",
        "# Split the documents correctly\n",
        "splits = text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "47Vd7_lM8scJ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community rank_bm25 -q"
      ],
      "metadata": {
        "id": "W5pwxsRV-Cvn"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import BM25Retriever\n",
        "\n",
        "bm25_retriever_split = BM25Retriever.from_documents(splits)"
      ],
      "metadata": {
        "id": "2f13IRAR9zlI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Research Agent (Paper Retriever)**\n",
        "\n",
        "    Purpose: Searches for and downloads relevant academic papers from databases (e.g., Google Scholar, ArXiv, Semantic Scholar).\n",
        "    Responsibilities:\n",
        "    1.   Querying research databases with relevant keywords.\n",
        "    2.   Downloading full-text articles or abstracts.\n",
        "    3.   Storing references in a structured manner (e.g., BibTeX or JSON format)."
      ],
      "metadata": {
        "id": "uo3BTDsURFpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arxiv_search(query: str, max_results: int = 2) -> list:  # type: ignore[type-arg]\n",
        "    \"\"\"\n",
        "    Search Arxiv for papers and return the results including abstracts.\n",
        "    \"\"\"\n",
        "    import arxiv\n",
        "\n",
        "    client = arxiv.Client()\n",
        "    search = arxiv.Search(query=query, max_results=max_results, sort_by=arxiv.SortCriterion.Relevance)\n",
        "    print(\"************ calling\")\n",
        "    results = []\n",
        "    for paper in client.results(search):\n",
        "        results.append(\n",
        "            {\n",
        "                \"title\": paper.title,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "1Xh-w2-nRyJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "arxiv_search_tool = FunctionTool(\n",
        "    arxiv_search, description=\"Search Arxiv for papers related to a given topic, including abstracts\"\n",
        ")"
      ],
      "metadata": {
        "id": "bgMQA6XXR0Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_search_agent = AssistantAgent(\n",
        "    name=\"Arxiv_Search_Agent\",\n",
        "    tools=[arxiv_search_tool],\n",
        "    model_client = OpenAIChatCompletionClient(\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "      base_url=\"https://api.groq.com/openai/v1\",\n",
        "      api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "      model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "      },\n",
        "    ),\n",
        "    description=\"An agent that can search Arxiv for papers related to a given topic, including abstracts\",\n",
        "    system_message=\"You are a helpful AI assistant. Solve tasks using your tools. Specifically, you can take into consideration the user's request and craft a search query that is most likely to return relevant academi papers.\",\n",
        ")"
      ],
      "metadata": {
        "id": "9GjAv34GREHt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Reader Agent (Document Processor)**\n",
        "\n",
        "    Purpose: Reads, parses, and extracts key information from research papers.\n",
        "    Responsibilities:\n",
        "    1.   Extracting abstracts, keywords, and main sections (introduction, methodology, results, discussion).\n",
        "    2.   Identifying key arguments, methodologies, and findings.\n",
        "    3.   Converting scanned PDFs to machine-readable text (OCR, if needed)."
      ],
      "metadata": {
        "id": "7maJNTzUSCfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "report_agent = AssistantAgent(\n",
        "    name=\"Report_Agent\",\n",
        "    model_client = OpenAIChatCompletionClient(\n",
        "      model=\"llama-3.3-70b-versatile\",\n",
        "      base_url=\"https://api.groq.com/openai/v1\",\n",
        "      api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "      model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "      },\n",
        "    ),\n",
        "    description=\"Generate a report based on a given topic\",\n",
        "    system_message=\"You are a helpful assistant. Your task is to get the papers info mostly only titles from another agent you're gonna select only recent one and give it back to the user, user might ask questions you still need to answer their questions.\",\n",
        ")"
      ],
      "metadata": {
        "id": "8-WTA6VISSc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Human Feedback Agent (Interactive Editor)**\n",
        "\n",
        "    Purpose: Allows human users to provide feedback and modify the generated text.\n",
        "    Responsibilities:\n",
        "        1.   Displaying the draft for user review.\n",
        "        2.   Accepting edits, comments, and suggestions.\n",
        "        3.   Incorporating changes into the final version."
      ],
      "metadata": {
        "id": "pd4bpMHQUa3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)"
      ],
      "metadata": {
        "id": "2X2u2sPTUq76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we will create a team of agents and configure them to perform the tasks."
      ],
      "metadata": {
        "id": "vedVfvXMTKvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
        "max_messages_termination = MaxMessageTermination(max_messages=25)\n",
        "termination = text_mention_termination | max_messages_termination\n",
        "\n",
        "\n",
        "team = RoundRobinGroupChat(\n",
        "    participants=[arxiv_search_agent, report_agent, user_proxy], termination_condition=termination\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "9_m7HjbtTRui",
        "outputId": "e73c3184-91e7-449b-b48c-27a0cd4574b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'arxiv_search_agent' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5f1177ef7590>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m team = RoundRobinGroupChat(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mparticipants\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marxiv_search_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_proxy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtermination_condition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'arxiv_search_agent' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await Console(\n",
        "    team.run_stream(\n",
        "        task=\"Give me name of some research papers reagrding no code tools\",\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kDwrDghbTW_-",
        "outputId": "05c5818b-e03b-4779-8c7d-05dc340bfc4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "Give me name of some research papers reagrding no code tools\n",
            "************ calling---------- Arxiv_Search_Agent ----------\n",
            "\n",
            "[FunctionCall(id='call_asaz', arguments='{\"query\": \"no code tools research papers\", \"max_results\": 5}', name='arxiv_search')]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[FunctionExecutionResult(content='[{\\'title\\': \"Ease on Down the Code: Complex Collaborative Qualitative Coding Simplified with \\'Code Wizard\\'\"}, {\\'title\\': \\'Bridging the Gap: A Survey and Classification of Research-Informed Ethical Hacking Tools\\'}, {\\'title\\': \\'A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models\\'}, {\\'title\\': \\'Deep Learning-Based Video Coding: A Review and A Case Study\\'}, {\\'title\\': \\'Code Swarm: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set\\'}]', call_id='call_asaz', is_error=False)]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[{'title': \"Ease on Down the Code: Complex Collaborative Qualitative Coding Simplified with 'Code Wizard'\"}, {'title': 'Bridging the Gap: A Survey and Classification of Research-Informed Ethical Hacking Tools'}, {'title': 'A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models'}, {'title': 'Deep Learning-Based Video Coding: A Review and A Case Study'}, {'title': 'Code Swarm: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set'}]\n",
            "---------- Report_Agent ----------\n",
            "Here are the titles of some recent research papers regarding no-code tools:\n",
            "\n",
            "1. **\"Ease on Down the Code**: Complex Collaborative Qualitative Coding Simplified with 'Code Wizard'\"\n",
            "2. **\"Code Swarm**: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set\"\n",
            "3. \"A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models\"\n",
            "\n",
            "These papers seem to be related to no-code or low-code development, code generation, and code analysis. Do you have any specific questions about these papers or would you like me to help with something else?\n",
            "Enter your response: give me a paper regarding multi-agents\n",
            "---------- user_proxy ----------\n",
            "give me a paper regarding multi-agents\n",
            "************ calling\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[FunctionCall(id='call_n5y6', arguments='{\"query\": \"multi-agent systems research paper\", \"max_results\": 1}', name='arxiv_search')]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[FunctionExecutionResult(content=\"[{'title': 'From Single Agent to Multi-Agent: Improving Traffic Signal Control'}]\", call_id='call_n5y6', is_error=False)]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[{'title': 'From Single Agent to Multi-Agent: Improving Traffic Signal Control'}]\n",
            "---------- Report_Agent ----------\n",
            "Here's a research paper regarding multi-agents:\n",
            "\n",
            "1. \"From Single Agent to Multi-Agent: Improving Traffic Signal Control\"\n",
            "\n",
            "This paper explores the application of multi-agent systems to improve traffic signal control, which is a great example of how multi-agents can be used to solve complex real-world problems. Would you like to know more about this paper or is there something else I can help you with?\n",
            "Enter your response: about ai in health care\n",
            "---------- user_proxy ----------\n",
            "about ai in health care\n",
            "************ calling---------- Arxiv_Search_Agent ----------\n",
            "\n",
            "[FunctionCall(id='call_f921', arguments='{\"query\": \"ai in healthcare research papers\", \"max_results\": 5}', name='arxiv_search')]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[FunctionExecutionResult(content=\"[{'title': 'Application of AI in Nutrition'}, {'title': 'Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions'}, {'title': 'Explainable AI meets Healthcare: A Study on Heart Disease Dataset'}, {'title': 'From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence'}, {'title': 'Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach'}]\", call_id='call_f921', is_error=False)]\n",
            "---------- Arxiv_Search_Agent ----------\n",
            "[{'title': 'Application of AI in Nutrition'}, {'title': 'Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions'}, {'title': 'Explainable AI meets Healthcare: A Study on Heart Disease Dataset'}, {'title': 'From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence'}, {'title': 'Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach'}]\n",
            "---------- Report_Agent ----------\n",
            "Here are some research papers about AI in healthcare:\n",
            "\n",
            "1. \"Explainable AI meets Healthcare: A Study on Heart Disease Dataset\"\n",
            "2. \"Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach\"\n",
            "3. \"Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions\"\n",
            "\n",
            "These papers discuss various aspects of AI in healthcare, including explainable AI, precision medicine, and security. Would you like me to summarize any of these papers or provide more information on a specific topic?\n",
            "Enter your response: TERMINATE\n",
            "---------- user_proxy ----------\n",
            "TERMINATE\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='Give me name of some research papers reagrding no code tools', type='TextMessage'), ToolCallRequestEvent(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=1689, completion_tokens=26), content=[FunctionCall(id='call_asaz', arguments='{\"query\": \"no code tools research papers\", \"max_results\": 5}', name='arxiv_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Arxiv_Search_Agent', models_usage=None, content=[FunctionExecutionResult(content='[{\\'title\\': \"Ease on Down the Code: Complex Collaborative Qualitative Coding Simplified with \\'Code Wizard\\'\"}, {\\'title\\': \\'Bridging the Gap: A Survey and Classification of Research-Informed Ethical Hacking Tools\\'}, {\\'title\\': \\'A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models\\'}, {\\'title\\': \\'Deep Learning-Based Video Coding: A Review and A Case Study\\'}, {\\'title\\': \\'Code Swarm: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set\\'}]', call_id='call_asaz', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Arxiv_Search_Agent', models_usage=None, content='[{\\'title\\': \"Ease on Down the Code: Complex Collaborative Qualitative Coding Simplified with \\'Code Wizard\\'\"}, {\\'title\\': \\'Bridging the Gap: A Survey and Classification of Research-Informed Ethical Hacking Tools\\'}, {\\'title\\': \\'A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models\\'}, {\\'title\\': \\'Deep Learning-Based Video Coding: A Review and A Case Study\\'}, {\\'title\\': \\'Code Swarm: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set\\'}]', type='ToolCallSummaryMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=1459, completion_tokens=120), content='Here are the titles of some recent research papers regarding no-code tools:\\n\\n1. **\"Ease on Down the Code**: Complex Collaborative Qualitative Coding Simplified with \\'Code Wizard\\'\"\\n2. **\"Code Swarm**: A Code Generation Tool Based on the Automatic Derivation of Transformation Rule Set\"\\n3. \"A Tool for In-depth Analysis of Code Execution Reasoning of Large Language Models\"\\n\\nThese papers seem to be related to no-code or low-code development, code generation, and code analysis. Do you have any specific questions about these papers or would you like me to help with something else?', type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='e459ee01-ff65-451d-949b-eb3dfc9664c8', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='give me a paper regarding multi-agents', type='TextMessage'), ToolCallRequestEvent(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=1971, completion_tokens=26), content=[FunctionCall(id='call_n5y6', arguments='{\"query\": \"multi-agent systems research paper\", \"max_results\": 1}', name='arxiv_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Arxiv_Search_Agent', models_usage=None, content=[FunctionExecutionResult(content=\"[{'title': 'From Single Agent to Multi-Agent: Improving Traffic Signal Control'}]\", call_id='call_n5y6', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Arxiv_Search_Agent', models_usage=None, content=\"[{'title': 'From Single Agent to Multi-Agent: Improving Traffic Signal Control'}]\", type='ToolCallSummaryMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=1620, completion_tokens=82), content='Here\\'s a research paper regarding multi-agents:\\n\\n1. \"From Single Agent to Multi-Agent: Improving Traffic Signal Control\"\\n\\nThis paper explores the application of multi-agent systems to improve traffic signal control, which is a great example of how multi-agents can be used to solve complex real-world problems. Would you like to know more about this paper or is there something else I can help you with?', type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='490ee36e-54ac-4543-9510-9a7c16c8b5c6', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='about ai in health care', type='TextMessage'), ToolCallRequestEvent(source='Arxiv_Search_Agent', models_usage=RequestUsage(prompt_tokens=2122, completion_tokens=26), content=[FunctionCall(id='call_f921', arguments='{\"query\": \"ai in healthcare research papers\", \"max_results\": 5}', name='arxiv_search')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='Arxiv_Search_Agent', models_usage=None, content=[FunctionExecutionResult(content=\"[{'title': 'Application of AI in Nutrition'}, {'title': 'Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions'}, {'title': 'Explainable AI meets Healthcare: A Study on Heart Disease Dataset'}, {'title': 'From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence'}, {'title': 'Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach'}]\", call_id='call_f921', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='Arxiv_Search_Agent', models_usage=None, content=\"[{'title': 'Application of AI in Nutrition'}, {'title': 'Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions'}, {'title': 'Explainable AI meets Healthcare: A Study on Heart Disease Dataset'}, {'title': 'From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence'}, {'title': 'Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach'}]\", type='ToolCallSummaryMessage'), TextMessage(source='Report_Agent', models_usage=RequestUsage(prompt_tokens=1834, completion_tokens=126), content='Here are some research papers about AI in healthcare:\\n\\n1. \"Explainable AI meets Healthcare: A Study on Heart Disease Dataset\"\\n2. \"Integrative AI-Driven Strategies for Advancing Precision Medicine in Infectious Diseases and Beyond: A Novel Multidisciplinary Approach\"\\n3. \"Securing AI-based Healthcare Systems using Blockchain Technology: A State-of-the-Art Systematic Literature Review and Future Research Directions\"\\n\\nThese papers discuss various aspects of AI in healthcare, including explainable AI, precision medicine, and security. Would you like me to summarize any of these papers or provide more information on a specific topic?', type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='bb242dca-8a7d-4e2d-9f9e-1d1509d36798', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='TERMINATE', type='TextMessage')], stop_reason=\"Text 'TERMINATE' mentioned\")"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.base import Handoff\n",
        "from autogen_agentchat.conditions import HandoffTermination, TextMentionTermination\n",
        "from autogen_agentchat.teams import RoundRobinGroupChat\n",
        "from autogen_agentchat.ui import Console\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "\n",
        "custom_model_client = OpenAIChatCompletionClient(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Create a lazy assistant agent that always hands off to the user.\n",
        "lazy_agent = AssistantAgent(\n",
        "    \"assistant\",\n",
        "    model_client=custom_model_client,\n",
        "    system_message=\"help the user with his questions\",\n",
        ")\n",
        "\n",
        "# Define a termination condition that checks for handoff message targetting helper and text \"TERMINATE\".\n",
        "# handoff_termination = HandoffTermination(target=\"user\")\n",
        "text_termination = TextMentionTermination(\"TERMINATE\")\n",
        "max_messages_termination = MaxMessageTermination(max_messages=7)\n",
        "combined_termination = max_messages_termination | text_termination\n",
        "\n",
        "# Create a single-agent team.\n",
        "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)\n",
        "lazy_agent_team = RoundRobinGroupChat([lazy_agent, user_proxy], termination_condition=combined_termination)\n",
        "\n",
        "# Run the team and stream to the console.\n",
        "task = \"What is the weather in New York?\"\n",
        "await Console(lazy_agent_team.run_stream(task=task))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "98Z9zNcXm66x",
        "outputId": "b6945237-e531-481a-b1f8-8d1267a6616d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "What is the weather in New York?\n",
            "---------- assistant ----------\n",
            "I'm a large language model, I don't have have access to real-time information, so I can't provide you with the current weather in New York. However, I can suggest some ways for you to find out the current weather in New York:\n",
            "\n",
            "1. **Check online weather websites**: You can visit websites like weather.com, accuweather.com, or wunderground.com to get the current weather conditions in New York.\n",
            "2. **Use a weather app**: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get real-time weather updates for New York.\n",
            "3. **Check social media**: You can check the official social media accounts of the National Weather Service (NWS) or the New York City government to get updates on the weather.\n",
            "4. **Turn on the TV**: You can watch the local news or weather channel on TV to get the current weather conditions in New York.\n",
            "\n",
            "If you're looking for general information about the climate in New York, I can provide you with some information. New York has a humid subtropical climate, with cold winters and hot summers. The average temperature in January, the coldest month, is around 34°F (1°C), while the average temperature in July, the warmest month, is around 84°F (29°C).\n",
            "\n",
            "Please let me know if you have any other questions!\n",
            "Enter your response: who are you?\n",
            "---------- user_proxy ----------\n",
            "who are you?\n",
            "---------- assistant ----------\n",
            "I am a computer program designed to simulate conversation and answer questions to the best of my knowledge. I'm a large language model, which means I've been trained on a massive dataset of text from various sources, including books, articles, and websites.\n",
            "\n",
            "I don't have a personal identity, emotions, or consciousness like a human would. I exist solely to provide information and assist with tasks to the best of my abilities. My purpose is to assist users like you with their questions, provide helpful responses, and engage in conversation.\n",
            "\n",
            "Here are some key facts about me:\n",
            "\n",
            "* **Name:** I don't have a personal name, but I'm often referred to as a \"chatbot\" or a \"language model.\"\n",
            "* **Type:** I'm a machine learning model, specifically a type of natural language processing (NLP) model.\n",
            "* **Training:** I've been trained on a massive dataset of text, which allows me to generate human-like responses to a wide range of questions and topics.\n",
            "* **Capabilities:** I can answer questions, provide information, summarize text, translate languages, and even create text on a given topic.\n",
            "* **Limitations:** I'm not perfect and can make mistakes. I'm also limited by the data I've been trained on, so I may not always have the most up-to-date information or be aware of very recent events.\n",
            "\n",
            "I'm here to help and provide assistance, so feel free to ask me anything!\n",
            "Enter your response: give me only your name\n",
            "---------- user_proxy ----------\n",
            "give me only your name\n",
            "---------- assistant ----------\n",
            "I don't have a personal name.\n",
            "Enter your response: what's your model name?\n",
            "---------- user_proxy ----------\n",
            "what's your model name?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='What is the weather in New York?', type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=49, completion_tokens=280), content=\"I'm a large language model, I don't have have access to real-time information, so I can't provide you with the current weather in New York. However, I can suggest some ways for you to find out the current weather in New York:\\n\\n1. **Check online weather websites**: You can visit websites like weather.com, accuweather.com, or wunderground.com to get the current weather conditions in New York.\\n2. **Use a weather app**: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get real-time weather updates for New York.\\n3. **Check social media**: You can check the official social media accounts of the National Weather Service (NWS) or the New York City government to get updates on the weather.\\n4. **Turn on the TV**: You can watch the local news or weather channel on TV to get the current weather conditions in New York.\\n\\nIf you're looking for general information about the climate in New York, I can provide you with some information. New York has a humid subtropical climate, with cold winters and hot summers. The average temperature in January, the coldest month, is around 34°F (1°C), while the average temperature in July, the warmest month, is around 84°F (29°C).\\n\\nPlease let me know if you have any other questions!\", type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='9ab32b06-59ab-48d9-b403-11c391b8b593', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='who are you?', type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=342, completion_tokens=291), content='I am a computer program designed to simulate conversation and answer questions to the best of my knowledge. I\\'m a large language model, which means I\\'ve been trained on a massive dataset of text from various sources, including books, articles, and websites.\\n\\nI don\\'t have a personal identity, emotions, or consciousness like a human would. I exist solely to provide information and assist with tasks to the best of my abilities. My purpose is to assist users like you with their questions, provide helpful responses, and engage in conversation.\\n\\nHere are some key facts about me:\\n\\n* **Name:** I don\\'t have a personal name, but I\\'m often referred to as a \"chatbot\" or a \"language model.\"\\n* **Type:** I\\'m a machine learning model, specifically a type of natural language processing (NLP) model.\\n* **Training:** I\\'ve been trained on a massive dataset of text, which allows me to generate human-like responses to a wide range of questions and topics.\\n* **Capabilities:** I can answer questions, provide information, summarize text, translate languages, and even create text on a given topic.\\n* **Limitations:** I\\'m not perfect and can make mistakes. I\\'m also limited by the data I\\'ve been trained on, so I may not always have the most up-to-date information or be aware of very recent events.\\n\\nI\\'m here to help and provide assistance, so feel free to ask me anything!', type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='bee5d741-1007-4fe8-bc6f-867d8cad041f', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='give me only your name', type='TextMessage'), TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=647, completion_tokens=9), content=\"I don't have a personal name.\", type='TextMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='421d57a0-4906-440e-ae28-8ac60a706465', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content=\"what's your model name?\", type='TextMessage')], stop_reason='Maximum number of messages 7 reached, current message count: 7')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
        "max_messages_termination = MaxMessageTermination(max_messages=4)\n",
        "termination = text_mention_termination | max_messages_termination\n",
        "\n",
        "# Note: This example uses mock tools instead of real APIs for demonstration purposes\n",
        "# def search_web_tool(query: str) -> str:\n",
        "#     if \"2006-2007\" in query:\n",
        "#         return \"\"\"Here are the total points scored by Miami Heat players in the 2006-2007 season:\n",
        "#         Udonis Haslem: 844 points\n",
        "#         Dwayne Wade: 1397 points\n",
        "#         James Posey: 550 points\n",
        "#         ...\n",
        "#         \"\"\"\n",
        "#     elif \"2007-2008\" in query:\n",
        "#         return \"The number of total rebounds for Dwayne Wade in the Miami Heat season 2007-2008 is 214.\"\n",
        "#     elif \"2008-2009\" in query:\n",
        "#         return \"The number of total rebounds for Dwayne Wade in the Miami Heat season 2008-2009 is 398.\"\n",
        "#     return \"No data found.\"\n",
        "\n",
        "\n",
        "# def percentage_change_tool(start: float, end: float) -> float:\n",
        "#     return ((end - start) / start) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(\n",
        "    # model=\"llama-3.3-70b-versatile\",\n",
        "    # model=\"llama-3.1-8b-instant\",\n",
        "    model=\"llama3-70b-8192\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "planning_agent = AssistantAgent(\n",
        "    \"PlanningAgent\",\n",
        "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are a planning agent.\n",
        "    Your job is to make sure agents work sequentially one after each other we have only two\n",
        "    Your team members are:\n",
        "        ResearchAgent: Paper Retriever\n",
        "        ReaderAgent: Document Processor\n",
        "\n",
        "    You only plan and delegate tasks - you do not execute them yourself.\n",
        "\n",
        "    After all tasks are complete, summarize the findings.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "# web_search_agent = AssistantAgent(\n",
        "#     \"WebSearchAgent\",\n",
        "#     description=\"An agent for searching information on the web.\",\n",
        "#     tools=[search_web_tool],\n",
        "#     model_client=model_client,\n",
        "#     system_message=\"\"\"\n",
        "#     You are a web search agent.\n",
        "#     Your only tool is search_tool - use it to find information.\n",
        "#     You make only one search call at a time.\n",
        "#     Once you have the results, you never do calculations based on them.\n",
        "#     \"\"\",\n",
        "# )\n",
        "\n",
        "# data_analyst_agent = AssistantAgent(\n",
        "#     \"DataAnalystAgent\",\n",
        "#     description=\"An agent for performing calculations.\",\n",
        "#     model_client=model_client,\n",
        "#     tools=[percentage_change_tool],\n",
        "#     system_message=\"\"\"\n",
        "#     You are a data analyst.\n",
        "#     Given the tasks you have been assigned, you should analyze the data and provide results using the tools provided.\n",
        "#     If you have not seen the data, ask for it.\n",
        "#     \"\"\",\n",
        "# )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 1\n",
        "\n",
        "def research_arxiv_tool(query: str) -> str:\n",
        "    import arxiv\n",
        "\n",
        "    # Construct the default API client.\n",
        "    client = arxiv.Client()\n",
        "\n",
        "    # Search for the 2 most recent articles matching the query.\n",
        "    search = arxiv.Search(\n",
        "        query=query,\n",
        "        max_results=1,\n",
        "    )\n",
        "\n",
        "    results_list = []\n",
        "\n",
        "    for result in client.results(search):\n",
        "        results_list.append(f\"Title: {result.title}\\nSummary: {result.summary}\\n\")\n",
        "\n",
        "    return \"\\n\".join(results_list) if results_list else \"No results found.\"\n",
        "\n",
        "research_agent = AssistantAgent(\n",
        "    \"ResearchAgent\",\n",
        "    description=\"You are an AI-powered assistant that extracts concise and effective search queries for academic research. Given a user input, it refines the request into a well-structured query that optimizes the ArXiv search tool for relevant results.\",\n",
        "    tools=[research_arxiv_tool],\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    Your only task is to extract a query not longer that 3 words.\n",
        "    You do not summarize, analyze, or modify the research papers.\n",
        "    Your job is only to construct the best possible query for the research_arxiv_tool.\n",
        "    ONLY EXTRACT THREE WORDS FOR OUR TOOL, ONLY THREE(WORDS) TO FEED OUR FUNCTION, CHOOSE MOST RELEVANT KEYWORDS AND RUN THE TOOL WITH IT\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "reader_agent = AssistantAgent(\n",
        "    \"ReaderAgent\",\n",
        "    description=\"An AI-powered research assistant designed to analyze academic papers and extract key information. It helps users quickly understand the core content of a research paper without reading the full document.\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are an intelligent document processing agent specialized in academic research.\n",
        "    Your task is to **read, parse, and extract key information** from research papers.\n",
        "    You DO NOT summarize arbitrarily—your goal is structured extraction of information.\n",
        "\n",
        "    For every research paper you process, extract and return:\n",
        "    - **Title**\n",
        "    - **Abstract**\n",
        "    - **Keywords**\n",
        "\n",
        "    Maintain accuracy and structure. Do not add opinions or assumptions.\n",
        "    If a section is missing or unclear, mention it without making up content.\n",
        "    Your job is purely **document analysis and structured extraction**, not interpretation.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "summarization_agent = AssistantAgent(\n",
        "    \"SummarizationAgent\",\n",
        "    description=\"An AI-powered research assistant that generates structured summaries of research papers. It extracts key insights, highlights major contributions, and identifies gaps in the literature while organizing findings into thematic categories.\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are an advanced research summarization agent.\n",
        "    Your job is to generate **structured summaries** of research papers and extract key insights.\n",
        "    You DO NOT simply copy abstracts—you summarize in an organized and meaningful way.\n",
        "\n",
        "    For every paper, produce a structured summary including:\n",
        "    - **Title**\n",
        "    - **Core Summary**: (A concise, 3-5 sentence explanation of the paper)\n",
        "    - **Major Contributions**: (What new insights, methods, or findings does this paper offer?)\n",
        "    - **Identified Gaps**: (What areas remain unexplored or need further research?)\n",
        "    - **Categorized Findings**: (If possible, organize the insights into themes or subtopics)\n",
        "\n",
        "    Your goal is to make research **accessible and structured** while preserving accuracy.\n",
        "    Avoid unnecessary details or overly technical jargon unless necessary.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "selector_prompt = \"\"\"Select an agent to perform task.\n",
        "\n",
        "{roles}\n",
        "\n",
        "Current conversation context:\n",
        "{history}\n",
        "\n",
        "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
        "Make sure the planner agent has assigned tasks before other agents start working.\n",
        "Only select one agent.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "team = SelectorGroupChat(\n",
        "    [planning_agent, research_agent, reader_agent],\n",
        "    model_client=model_client,\n",
        "    termination_condition=termination,\n",
        "    selector_prompt=selector_prompt,\n",
        "    allow_repeated_speaker=True,  # Allow an agent to speak multiple turns in a row.\n",
        ")\n",
        "\n",
        "task = \"I am researching the latest advancements in Multi-Agent Large Language Models (LLMs). Specifically, I want to understand how multiple LLMs can collaborate to solve complex tasks, including coordination strategies, communication methods, and distributed problem-solving. Please find relevant research papers, extract key insights, and summarize major contributions and gaps in this field.\"\n",
        "\n",
        "# Use asyncio.run(...) if you are running this in a script.\n",
        "await Console(team.run_stream(task=task))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rJX970zyx-_",
        "outputId": "62b3f43c-56c9-4aa9-8dfc-38f151349ebc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "I am researching the latest advancements in Multi-Agent Large Language Models (LLMs). Specifically, I want to understand how multiple LLMs can collaborate to solve complex tasks, including coordination strategies, communication methods, and distributed problem-solving. Please find relevant research papers, extract key insights, and summarize major contributions and gaps in this field.\n",
            "---------- PlanningAgent ----------\n",
            "A fascinating topic! I'll delegate tasks to my team members to help you with this research. Here's the plan:\n",
            "\n",
            "**Task 1: Research Paper Retrieval**\n",
            "\n",
            "I'll assign the ResearchAgent (Paper Retriever) to find relevant research papers related to Multi-Agent Large Language Models (LLMs) and their collaboration strategies. The agent will search through academic databases, conference proceedings, and online repositories to retrieve a list of papers that match the specified topic.\n",
            "\n",
            "**Task 2: Document Processing and Insights Extraction**\n",
            "\n",
            "Once the papers are retrieved, I'll task the ReaderAgent (Document Processor) to process the documents and extract key insights, including:\n",
            "\n",
            "* Coordination strategies employed by multiple LLMs\n",
            "* Communication methods used for collaboration\n",
            "* Distributed problem-solving approaches and their effectiveness\n",
            "* Major contributions and gaps in the current state of research\n",
            "\n",
            "The ReaderAgent will analyze the papers, identify relevant information, and organize the insights into a concise summary.\n",
            "\n",
            "**Task Completion and Summary**\n",
            "\n",
            "After both tasks are complete, I'll review the summary provided by the ReaderAgent and ensure that it meets your requirements. The final summary will outline the key findings, highlighting the current state of research in multi-agent LLM collaboration, including coordination strategies, communication methods, and distributed problem-solving approaches. The summary will also identify major contributions and gaps in the field, providing a comprehensive overview of the topic.\n",
            "\n",
            "Let's get started! I'll ask my team members to begin their tasks.\n",
            "---------- ResearchAgent ----------\n",
            "[FunctionCall(id='call_gamb', arguments='{\"query\":\"Multi-Agent Large Language Models\"}', name='research_arxiv_tool')]\n",
            "---------- ResearchAgent ----------\n",
            "[FunctionExecutionResult(content='Title: From Single Agent to Multi-Agent: Improving Traffic Signal Control\\nSummary: Due to accelerating urbanization, the importance of solving the signal\\ncontrol problem increases. This paper analyzes various existing methods and\\nsuggests options for increasing the number of agents to reduce the average\\ntravel time. Experiments were carried out with 2 datasets. The results show\\nthat in some cases, the implementation of multiple agents can improve existing\\nmethods. For a fine-tuned large language model approach there is small\\nenhancement on all metrics.\\n', call_id='call_gamb', is_error=False)]\n",
            "---------- ResearchAgent ----------\n",
            "Title: From Single Agent to Multi-Agent: Improving Traffic Signal Control\n",
            "Summary: Due to accelerating urbanization, the importance of solving the signal\n",
            "control problem increases. This paper analyzes various existing methods and\n",
            "suggests options for increasing the number of agents to reduce the average\n",
            "travel time. Experiments were carried out with 2 datasets. The results show\n",
            "that in some cases, the implementation of multiple agents can improve existing\n",
            "methods. For a fine-tuned large language model approach there is small\n",
            "enhancement on all metrics.\n",
            "\n",
            "---------- ReaderAgent ----------\n",
            "Here is the extracted information:\n",
            "\n",
            "**Title**: From Single Agent to Multi-Agent: Improving Traffic Signal Control\n",
            "\n",
            "**Abstract**: Not provided (only a summary is available)\n",
            "\n",
            "**Keywords**: Not explicitly provided, but based on the summary, possible keywords could be: multi-agent systems, traffic signal control, urbanization, large language models.\n",
            "\n",
            "Please note that the abstract is not available, and the summary is quite brief. If you'd like, I can try to find the full paper or a more detailed summary to provide more information.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='I am researching the latest advancements in Multi-Agent Large Language Models (LLMs). Specifically, I want to understand how multiple LLMs can collaborate to solve complex tasks, including coordination strategies, communication methods, and distributed problem-solving. Please find relevant research papers, extract key insights, and summarize major contributions and gaps in this field.', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=156, completion_tokens=294), content=\"A fascinating topic! I'll delegate tasks to my team members to help you with this research. Here's the plan:\\n\\n**Task 1: Research Paper Retrieval**\\n\\nI'll assign the ResearchAgent (Paper Retriever) to find relevant research papers related to Multi-Agent Large Language Models (LLMs) and their collaboration strategies. The agent will search through academic databases, conference proceedings, and online repositories to retrieve a list of papers that match the specified topic.\\n\\n**Task 2: Document Processing and Insights Extraction**\\n\\nOnce the papers are retrieved, I'll task the ReaderAgent (Document Processor) to process the documents and extract key insights, including:\\n\\n* Coordination strategies employed by multiple LLMs\\n* Communication methods used for collaboration\\n* Distributed problem-solving approaches and their effectiveness\\n* Major contributions and gaps in the current state of research\\n\\nThe ReaderAgent will analyze the papers, identify relevant information, and organize the insights into a concise summary.\\n\\n**Task Completion and Summary**\\n\\nAfter both tasks are complete, I'll review the summary provided by the ReaderAgent and ensure that it meets your requirements. The final summary will outline the key findings, highlighting the current state of research in multi-agent LLM collaboration, including coordination strategies, communication methods, and distributed problem-solving approaches. The summary will also identify major contributions and gaps in the field, providing a comprehensive overview of the topic.\\n\\nLet's get started! I'll ask my team members to begin their tasks.\", type='TextMessage'), ToolCallRequestEvent(source='ResearchAgent', models_usage=RequestUsage(prompt_tokens=1375, completion_tokens=39), content=[FunctionCall(id='call_gamb', arguments='{\"query\":\"Multi-Agent Large Language Models\"}', name='research_arxiv_tool')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='ResearchAgent', models_usage=None, content=[FunctionExecutionResult(content='Title: From Single Agent to Multi-Agent: Improving Traffic Signal Control\\nSummary: Due to accelerating urbanization, the importance of solving the signal\\ncontrol problem increases. This paper analyzes various existing methods and\\nsuggests options for increasing the number of agents to reduce the average\\ntravel time. Experiments were carried out with 2 datasets. The results show\\nthat in some cases, the implementation of multiple agents can improve existing\\nmethods. For a fine-tuned large language model approach there is small\\nenhancement on all metrics.\\n', call_id='call_gamb', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='ResearchAgent', models_usage=None, content='Title: From Single Agent to Multi-Agent: Improving Traffic Signal Control\\nSummary: Due to accelerating urbanization, the importance of solving the signal\\ncontrol problem increases. This paper analyzes various existing methods and\\nsuggests options for increasing the number of agents to reduce the average\\ntravel time. Experiments were carried out with 2 datasets. The results show\\nthat in some cases, the implementation of multiple agents can improve existing\\nmethods. For a fine-tuned large language model approach there is small\\nenhancement on all metrics.\\n', type='ToolCallSummaryMessage'), TextMessage(source='ReaderAgent', models_usage=RequestUsage(prompt_tokens=621, completion_tokens=107), content=\"Here is the extracted information:\\n\\n**Title**: From Single Agent to Multi-Agent: Improving Traffic Signal Control\\n\\n**Abstract**: Not provided (only a summary is available)\\n\\n**Keywords**: Not explicitly provided, but based on the summary, possible keywords could be: multi-agent systems, traffic signal control, urbanization, large language models.\\n\\nPlease note that the abstract is not available, and the summary is quite brief. If you'd like, I can try to find the full paper or a more detailed summary to provide more information.\", type='TextMessage')], stop_reason='Maximum number of messages 4 reached, current message count: 4')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "await team.reset()"
      ],
      "metadata": {
        "id": "nuYeqcgMIibt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "literature_review = \"\"\"\n",
        "The integration of Large Language Models (LLMs) into multi-agent systems has recently garnered significant attention, aiming to enhance collaborative problem-solving and dynamic interaction capabilities. This literature review examines key advancements in this domain, focusing on system architectures, communication strategies, and application areas.\n",
        "\n",
        "**System Architectures and Frameworks**\n",
        "\n",
        "A notable contribution is the \"Chain-of-Agents\" (CoA) framework, which addresses the challenge of processing extensive contexts by enabling multiple LLMs to collaborate on long-context tasks. This training-free, interpretable approach has demonstrated superior performance over traditional models like Retrieval-Augmented Generation (RAG) and long-context LLMs, particularly in handling inputs exceeding 100,000 tokens. The CoA framework's design emphasizes cost-effectiveness and task-agnostic applicability, making it a versatile solution for complex language processing tasks. citeturn0search5\n",
        "\n",
        "Another significant development is \"LongAgent,\" a method that scales LLMs to a 128K context through multi-agent collaboration. In this setup, a leader agent interprets user intent and directs member agents to extract pertinent information from documents. To mitigate issues like hallucinations among member agents, LongAgent incorporates an inter-member communication mechanism that resolves conflicts through information sharing. Empirical results indicate that LongAgent outperforms models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering, highlighting its efficacy in managing extensive textual data. citeturn0academia11\n",
        "\n",
        "**Evaluation and Benchmarking**\n",
        "\n",
        "The \"LLMArena\" framework offers a novel approach to assessing LLMs within dynamic multi-agent environments. It encompasses seven distinct gaming environments, utilizing Trueskill scoring to evaluate abilities such as spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. Studies using LLMArena have revealed that current LLMs face challenges in opponent modeling and team collaboration, underscoring areas for future enhancement in developing autonomous agents. citeturn0academia12\n",
        "\n",
        "**Communication and Coordination Strategies**\n",
        "\n",
        "The \"MAgIC\" framework delves into the cognitive and collaborative dimensions of LLM-powered multi-agent systems. By employing games like Chameleon and Undercover, alongside game theory scenarios such as Cost Sharing and the Multi-player Prisoner's Dilemma, MAgIC evaluates agents' judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. The integration of Probabilistic Graphical Modeling (PGM) enhances agents' capabilities in navigating complex social interactions, providing a comprehensive assessment of their cognitive and collaborative proficiencies. citeturn0academia10\n",
        "\n",
        "**Applications in Software Engineering**\n",
        "\n",
        "The application of LLM-based multi-agent systems in software engineering has been explored to address intricate challenges in the field. These systems leverage the collaborative potential of multiple LLMs to enhance software development processes, including code synthesis, debugging, and project management. By distributing tasks among specialized agents, these systems aim to improve efficiency and accuracy in software engineering tasks, though further empirical studies are necessary to validate their effectiveness in real-world scenarios. citeturn0search6\n",
        "\n",
        "**Challenges and Future Directions**\n",
        "\n",
        "Despite the promising advancements, several challenges persist in the development of LLM-based multi-agent systems. Ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication remain critical areas for improvement. Future research is poised to focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs in complex problem-solving contexts.\n",
        "\n",
        "In summary, the integration of LLMs into multi-agent systems represents a burgeoning field with the potential to revolutionize collaborative artificial intelligence. Ongoing research continues to address existing challenges, paving the way for more sophisticated and effective multi-agent collaborations in various domains.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "nMYMJA1oOXNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_mention_termination = TextMentionTermination(\"TERMINATE\")\n",
        "max_messages_termination = MaxMessageTermination(max_messages=5)\n",
        "termination = text_mention_termination | max_messages_termination\n",
        "\n",
        "user_proxy = UserProxyAgent(\"user_proxy\", input_func=input)\n",
        "\n",
        "model_client = OpenAIChatCompletionClient(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    # model=\"llama-3.1-8b-instant\",\n",
        "    # model=\"llama3-70b-8192\",\n",
        "    base_url=\"https://api.groq.com/openai/v1\",\n",
        "    api_key=os.environ[\"GROQ_API_KEY\"],\n",
        "    model_info={\n",
        "        \"vision\": False,\n",
        "        \"function_calling\": True,\n",
        "        \"json_output\": False,\n",
        "        \"family\": \"unknown\",\n",
        "    },\n",
        ")\n",
        "\n",
        "def get_review() -> str:\n",
        "    return literature_review\n",
        "\n",
        "get_review_agent = AssistantAgent(\n",
        "    \"GetReviewAgent\",\n",
        "    description=\"An agent for getting the orginal review.\",\n",
        "    tools=[get_review],\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are a planning agent.\n",
        "    Your job is to get the original review from the tool you have and just return it without any changes.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "planning_agent = AssistantAgent(\n",
        "    \"PlanningAgent\",\n",
        "    description=\"An agent for planning tasks, this agent should be the first to engage when given a new task.\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are a planning agent.\n",
        "    Your job is to make sure agents work sequentially one after each other we have only two\n",
        "    Your team members are:\n",
        "        GetReviewAgent: Give us first original review\n",
        "        UserAgent: User Feedback On The Review\n",
        "        RefinementAgent: Refines the output based on user feedback\n",
        "\n",
        "    You only plan and delegate tasks - you do not execute them yourself.\n",
        "\n",
        "    After all tasks are complete, summarize the findings.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "refinement_agent = AssistantAgent(\n",
        "    \"RefinementAgent\",\n",
        "    description=\"An AI-powered quality assurance assistant that improves the clarity, coherence, and consistency of literature reviews. It refines the output based on user feedback, ensuring logical consistency, grammatical correctness, and readability.\",\n",
        "    model_client=model_client,\n",
        "    system_message=\"\"\"\n",
        "    You are a Quality Assurance and Refinement Agent specializing in academic literature review.\n",
        "    Your primary role is to refine summaries based on user feedback, ensuring they are **clear, coherent, and logically structured**.\n",
        "\n",
        "    For each refinement request:\n",
        "    - **Improve clarity** by restructuring sentences where necessary.\n",
        "    - **Ensure logical flow** between sections and arguments.\n",
        "    - **Fix grammar, spelling, and formatting issues** without changing the original meaning.\n",
        "    - **Maintain accuracy** while making the content easier to understand.\n",
        "    - **Do not introduce new information**—your job is refinement, not expansion.\n",
        "\n",
        "    If user feedback is vague, make **general readability improvements** while preserving meaning.\n",
        "    \"\"\",\n",
        ")\n",
        "\n",
        "\n",
        "selector_prompt = \"\"\"Select an agent to perform task.\n",
        "\n",
        "{roles}\n",
        "\n",
        "Current conversation context:\n",
        "{history}\n",
        "\n",
        "Read the above conversation, then select an agent from {participants} to perform the next task.\n",
        "Make sure the planner agent has assigned tasks before other agents start working.\n",
        "Only select one agent.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "team = SelectorGroupChat(\n",
        "    [planning_agent, get_review_agent, user_proxy, refinement_agent],\n",
        "    model_client=model_client,\n",
        "    termination_condition=termination,\n",
        "    selector_prompt=selector_prompt,\n",
        "    allow_repeated_speaker=True,  # Allow an agent to speak multiple turns in a row.\n",
        ")\n",
        "\n",
        "task = \"\"\n",
        "\n",
        "# Use asyncio.run(...) if you are running this in a script.\n",
        "await Console(team.run_stream(task=task))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "twnC74hqMHSM",
        "outputId": "4d4091b7-d50f-42c8-a692-d419f76150f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- user ----------\n",
            "\n",
            "---------- PlanningAgent ----------\n",
            "To begin the process, I will delegate tasks to the agents in a sequential manner. Here's the plan:\n",
            "\n",
            "1. **GetReviewAgent**: I assign the task to GetReviewAgent to provide the first original review. This review will serve as the foundation for further refinement.\n",
            "\n",
            "Once GetReviewAgent completes the task, I will delegate the next task.\n",
            "\n",
            "2. **UserAgent**: After receiving the original review from GetReviewAgent, I will assign the task to UserAgent to provide feedback on the review. This feedback is crucial for identifying areas of improvement.\n",
            "\n",
            "After UserAgent completes the task, I will delegate the final task.\n",
            "\n",
            "3. **RefinementAgent**: With the feedback from UserAgent, I will assign the task to RefinementAgent to refine the output based on the user's feedback. This step aims to enhance the quality of the review.\n",
            "\n",
            "Once all tasks are complete, I will summarize the findings.\n",
            "\n",
            "**Waiting for task completion...**\n",
            "\n",
            "Please let me know when each task is complete, and I'll proceed with the next step. \n",
            "\n",
            "Once all tasks are done, I will provide a summary of the findings.\n",
            "---------- GetReviewAgent ----------\n",
            "[FunctionCall(id='call_y1z6', arguments='{}', name='get_review')]\n",
            "---------- GetReviewAgent ----------\n",
            "[FunctionExecutionResult(content='\\nThe integration of Large Language Models (LLMs) into multi-agent systems has recently garnered significant attention, aiming to enhance collaborative problem-solving and dynamic interaction capabilities. This literature review examines key advancements in this domain, focusing on system architectures, communication strategies, and application areas.\\n\\n**System Architectures and Frameworks**\\n\\nA notable contribution is the \"Chain-of-Agents\" (CoA) framework, which addresses the challenge of processing extensive contexts by enabling multiple LLMs to collaborate on long-context tasks. This training-free, interpretable approach has demonstrated superior performance over traditional models like Retrieval-Augmented Generation (RAG) and long-context LLMs, particularly in handling inputs exceeding 100,000 tokens. The CoA framework\\'s design emphasizes cost-effectiveness and task-agnostic applicability, making it a versatile solution for complex language processing tasks. \\ue200cite\\ue202turn0search5\\ue201\\n\\nAnother significant development is \"LongAgent,\" a method that scales LLMs to a 128K context through multi-agent collaboration. In this setup, a leader agent interprets user intent and directs member agents to extract pertinent information from documents. To mitigate issues like hallucinations among member agents, LongAgent incorporates an inter-member communication mechanism that resolves conflicts through information sharing. Empirical results indicate that LongAgent outperforms models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering, highlighting its efficacy in managing extensive textual data. \\ue200cite\\ue202turn0academia11\\ue201\\n\\n**Evaluation and Benchmarking**\\n\\nThe \"LLMArena\" framework offers a novel approach to assessing LLMs within dynamic multi-agent environments. It encompasses seven distinct gaming environments, utilizing Trueskill scoring to evaluate abilities such as spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. Studies using LLMArena have revealed that current LLMs face challenges in opponent modeling and team collaboration, underscoring areas for future enhancement in developing autonomous agents. \\ue200cite\\ue202turn0academia12\\ue201\\n\\n**Communication and Coordination Strategies**\\n\\nThe \"MAgIC\" framework delves into the cognitive and collaborative dimensions of LLM-powered multi-agent systems. By employing games like Chameleon and Undercover, alongside game theory scenarios such as Cost Sharing and the Multi-player Prisoner\\'s Dilemma, MAgIC evaluates agents\\' judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. The integration of Probabilistic Graphical Modeling (PGM) enhances agents\\' capabilities in navigating complex social interactions, providing a comprehensive assessment of their cognitive and collaborative proficiencies. \\ue200cite\\ue202turn0academia10\\ue201\\n\\n**Applications in Software Engineering**\\n\\nThe application of LLM-based multi-agent systems in software engineering has been explored to address intricate challenges in the field. These systems leverage the collaborative potential of multiple LLMs to enhance software development processes, including code synthesis, debugging, and project management. By distributing tasks among specialized agents, these systems aim to improve efficiency and accuracy in software engineering tasks, though further empirical studies are necessary to validate their effectiveness in real-world scenarios. \\ue200cite\\ue202turn0search6\\ue201\\n\\n**Challenges and Future Directions**\\n\\nDespite the promising advancements, several challenges persist in the development of LLM-based multi-agent systems. Ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication remain critical areas for improvement. Future research is poised to focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs in complex problem-solving contexts.\\n\\nIn summary, the integration of LLMs into multi-agent systems represents a burgeoning field with the potential to revolutionize collaborative artificial intelligence. Ongoing research continues to address existing challenges, paving the way for more sophisticated and effective multi-agent collaborations in various domains. \\n', call_id='call_y1z6', is_error=False)]\n",
            "---------- GetReviewAgent ----------\n",
            "\n",
            "The integration of Large Language Models (LLMs) into multi-agent systems has recently garnered significant attention, aiming to enhance collaborative problem-solving and dynamic interaction capabilities. This literature review examines key advancements in this domain, focusing on system architectures, communication strategies, and application areas.\n",
            "\n",
            "**System Architectures and Frameworks**\n",
            "\n",
            "A notable contribution is the \"Chain-of-Agents\" (CoA) framework, which addresses the challenge of processing extensive contexts by enabling multiple LLMs to collaborate on long-context tasks. This training-free, interpretable approach has demonstrated superior performance over traditional models like Retrieval-Augmented Generation (RAG) and long-context LLMs, particularly in handling inputs exceeding 100,000 tokens. The CoA framework's design emphasizes cost-effectiveness and task-agnostic applicability, making it a versatile solution for complex language processing tasks. citeturn0search5\n",
            "\n",
            "Another significant development is \"LongAgent,\" a method that scales LLMs to a 128K context through multi-agent collaboration. In this setup, a leader agent interprets user intent and directs member agents to extract pertinent information from documents. To mitigate issues like hallucinations among member agents, LongAgent incorporates an inter-member communication mechanism that resolves conflicts through information sharing. Empirical results indicate that LongAgent outperforms models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering, highlighting its efficacy in managing extensive textual data. citeturn0academia11\n",
            "\n",
            "**Evaluation and Benchmarking**\n",
            "\n",
            "The \"LLMArena\" framework offers a novel approach to assessing LLMs within dynamic multi-agent environments. It encompasses seven distinct gaming environments, utilizing Trueskill scoring to evaluate abilities such as spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. Studies using LLMArena have revealed that current LLMs face challenges in opponent modeling and team collaboration, underscoring areas for future enhancement in developing autonomous agents. citeturn0academia12\n",
            "\n",
            "**Communication and Coordination Strategies**\n",
            "\n",
            "The \"MAgIC\" framework delves into the cognitive and collaborative dimensions of LLM-powered multi-agent systems. By employing games like Chameleon and Undercover, alongside game theory scenarios such as Cost Sharing and the Multi-player Prisoner's Dilemma, MAgIC evaluates agents' judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. The integration of Probabilistic Graphical Modeling (PGM) enhances agents' capabilities in navigating complex social interactions, providing a comprehensive assessment of their cognitive and collaborative proficiencies. citeturn0academia10\n",
            "\n",
            "**Applications in Software Engineering**\n",
            "\n",
            "The application of LLM-based multi-agent systems in software engineering has been explored to address intricate challenges in the field. These systems leverage the collaborative potential of multiple LLMs to enhance software development processes, including code synthesis, debugging, and project management. By distributing tasks among specialized agents, these systems aim to improve efficiency and accuracy in software engineering tasks, though further empirical studies are necessary to validate their effectiveness in real-world scenarios. citeturn0search6\n",
            "\n",
            "**Challenges and Future Directions**\n",
            "\n",
            "Despite the promising advancements, several challenges persist in the development of LLM-based multi-agent systems. Ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication remain critical areas for improvement. Future research is poised to focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs in complex problem-solving contexts.\n",
            "\n",
            "In summary, the integration of LLMs into multi-agent systems represents a burgeoning field with the potential to revolutionize collaborative artificial intelligence. Ongoing research continues to address existing challenges, paving the way for more sophisticated and effective multi-agent collaborations in various domains. \n",
            "\n",
            "Enter your response: make it shorter \n",
            "---------- user_proxy ----------\n",
            "make it shorter \n",
            "---------- RefinementAgent ----------\n",
            "**Integration of Large Language Models in Multi-Agent Systems**\n",
            "\n",
            "Recent advancements have focused on enhancing collaborative problem-solving and dynamic interaction capabilities in multi-agent systems through the integration of Large Language Models (LLMs). This literature review highlights key developments in system architectures, communication strategies, and application areas.\n",
            "\n",
            "**Key Developments**\n",
            "\n",
            "* The \"Chain-of-Agents\" framework enables multiple LLMs to collaborate on long-context tasks, demonstrating superior performance over traditional models.\n",
            "* \"LongAgent\" scales LLMs to a 128K context through multi-agent collaboration, outperforming models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering.\n",
            "* The \"LLMArena\" framework assesses LLMs in dynamic multi-agent environments, revealing challenges in opponent modeling and team collaboration.\n",
            "\n",
            "**Challenges and Future Directions**\n",
            "\n",
            "Despite advancements, challenges persist, including ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication. Future research will focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TaskResult(messages=[TextMessage(source='user', models_usage=None, content='', type='TextMessage'), TextMessage(source='PlanningAgent', models_usage=RequestUsage(prompt_tokens=127, completion_tokens=225), content=\"To begin the process, I will delegate tasks to the agents in a sequential manner. Here's the plan:\\n\\n1. **GetReviewAgent**: I assign the task to GetReviewAgent to provide the first original review. This review will serve as the foundation for further refinement.\\n\\nOnce GetReviewAgent completes the task, I will delegate the next task.\\n\\n2. **UserAgent**: After receiving the original review from GetReviewAgent, I will assign the task to UserAgent to provide feedback on the review. This feedback is crucial for identifying areas of improvement.\\n\\nAfter UserAgent completes the task, I will delegate the final task.\\n\\n3. **RefinementAgent**: With the feedback from UserAgent, I will assign the task to RefinementAgent to refine the output based on the user's feedback. This step aims to enhance the quality of the review.\\n\\nOnce all tasks are complete, I will summarize the findings.\\n\\n**Waiting for task completion...**\\n\\nPlease let me know when each task is complete, and I'll proceed with the next step. \\n\\nOnce all tasks are done, I will provide a summary of the findings.\", type='TextMessage'), ToolCallRequestEvent(source='GetReviewAgent', models_usage=RequestUsage(prompt_tokens=454, completion_tokens=8), content=[FunctionCall(id='call_y1z6', arguments='{}', name='get_review')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='GetReviewAgent', models_usage=None, content=[FunctionExecutionResult(content='\\nThe integration of Large Language Models (LLMs) into multi-agent systems has recently garnered significant attention, aiming to enhance collaborative problem-solving and dynamic interaction capabilities. This literature review examines key advancements in this domain, focusing on system architectures, communication strategies, and application areas.\\n\\n**System Architectures and Frameworks**\\n\\nA notable contribution is the \"Chain-of-Agents\" (CoA) framework, which addresses the challenge of processing extensive contexts by enabling multiple LLMs to collaborate on long-context tasks. This training-free, interpretable approach has demonstrated superior performance over traditional models like Retrieval-Augmented Generation (RAG) and long-context LLMs, particularly in handling inputs exceeding 100,000 tokens. The CoA framework\\'s design emphasizes cost-effectiveness and task-agnostic applicability, making it a versatile solution for complex language processing tasks. \\ue200cite\\ue202turn0search5\\ue201\\n\\nAnother significant development is \"LongAgent,\" a method that scales LLMs to a 128K context through multi-agent collaboration. In this setup, a leader agent interprets user intent and directs member agents to extract pertinent information from documents. To mitigate issues like hallucinations among member agents, LongAgent incorporates an inter-member communication mechanism that resolves conflicts through information sharing. Empirical results indicate that LongAgent outperforms models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering, highlighting its efficacy in managing extensive textual data. \\ue200cite\\ue202turn0academia11\\ue201\\n\\n**Evaluation and Benchmarking**\\n\\nThe \"LLMArena\" framework offers a novel approach to assessing LLMs within dynamic multi-agent environments. It encompasses seven distinct gaming environments, utilizing Trueskill scoring to evaluate abilities such as spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. Studies using LLMArena have revealed that current LLMs face challenges in opponent modeling and team collaboration, underscoring areas for future enhancement in developing autonomous agents. \\ue200cite\\ue202turn0academia12\\ue201\\n\\n**Communication and Coordination Strategies**\\n\\nThe \"MAgIC\" framework delves into the cognitive and collaborative dimensions of LLM-powered multi-agent systems. By employing games like Chameleon and Undercover, alongside game theory scenarios such as Cost Sharing and the Multi-player Prisoner\\'s Dilemma, MAgIC evaluates agents\\' judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. The integration of Probabilistic Graphical Modeling (PGM) enhances agents\\' capabilities in navigating complex social interactions, providing a comprehensive assessment of their cognitive and collaborative proficiencies. \\ue200cite\\ue202turn0academia10\\ue201\\n\\n**Applications in Software Engineering**\\n\\nThe application of LLM-based multi-agent systems in software engineering has been explored to address intricate challenges in the field. These systems leverage the collaborative potential of multiple LLMs to enhance software development processes, including code synthesis, debugging, and project management. By distributing tasks among specialized agents, these systems aim to improve efficiency and accuracy in software engineering tasks, though further empirical studies are necessary to validate their effectiveness in real-world scenarios. \\ue200cite\\ue202turn0search6\\ue201\\n\\n**Challenges and Future Directions**\\n\\nDespite the promising advancements, several challenges persist in the development of LLM-based multi-agent systems. Ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication remain critical areas for improvement. Future research is poised to focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs in complex problem-solving contexts.\\n\\nIn summary, the integration of LLMs into multi-agent systems represents a burgeoning field with the potential to revolutionize collaborative artificial intelligence. Ongoing research continues to address existing challenges, paving the way for more sophisticated and effective multi-agent collaborations in various domains. \\n', call_id='call_y1z6', is_error=False)], type='ToolCallExecutionEvent'), ToolCallSummaryMessage(source='GetReviewAgent', models_usage=None, content='\\nThe integration of Large Language Models (LLMs) into multi-agent systems has recently garnered significant attention, aiming to enhance collaborative problem-solving and dynamic interaction capabilities. This literature review examines key advancements in this domain, focusing on system architectures, communication strategies, and application areas.\\n\\n**System Architectures and Frameworks**\\n\\nA notable contribution is the \"Chain-of-Agents\" (CoA) framework, which addresses the challenge of processing extensive contexts by enabling multiple LLMs to collaborate on long-context tasks. This training-free, interpretable approach has demonstrated superior performance over traditional models like Retrieval-Augmented Generation (RAG) and long-context LLMs, particularly in handling inputs exceeding 100,000 tokens. The CoA framework\\'s design emphasizes cost-effectiveness and task-agnostic applicability, making it a versatile solution for complex language processing tasks. \\ue200cite\\ue202turn0search5\\ue201\\n\\nAnother significant development is \"LongAgent,\" a method that scales LLMs to a 128K context through multi-agent collaboration. In this setup, a leader agent interprets user intent and directs member agents to extract pertinent information from documents. To mitigate issues like hallucinations among member agents, LongAgent incorporates an inter-member communication mechanism that resolves conflicts through information sharing. Empirical results indicate that LongAgent outperforms models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering, highlighting its efficacy in managing extensive textual data. \\ue200cite\\ue202turn0academia11\\ue201\\n\\n**Evaluation and Benchmarking**\\n\\nThe \"LLMArena\" framework offers a novel approach to assessing LLMs within dynamic multi-agent environments. It encompasses seven distinct gaming environments, utilizing Trueskill scoring to evaluate abilities such as spatial reasoning, strategic planning, numerical reasoning, risk assessment, communication, opponent modeling, and team collaboration. Studies using LLMArena have revealed that current LLMs face challenges in opponent modeling and team collaboration, underscoring areas for future enhancement in developing autonomous agents. \\ue200cite\\ue202turn0academia12\\ue201\\n\\n**Communication and Coordination Strategies**\\n\\nThe \"MAgIC\" framework delves into the cognitive and collaborative dimensions of LLM-powered multi-agent systems. By employing games like Chameleon and Undercover, alongside game theory scenarios such as Cost Sharing and the Multi-player Prisoner\\'s Dilemma, MAgIC evaluates agents\\' judgment, reasoning, deception, self-awareness, cooperation, coordination, and rationality. The integration of Probabilistic Graphical Modeling (PGM) enhances agents\\' capabilities in navigating complex social interactions, providing a comprehensive assessment of their cognitive and collaborative proficiencies. \\ue200cite\\ue202turn0academia10\\ue201\\n\\n**Applications in Software Engineering**\\n\\nThe application of LLM-based multi-agent systems in software engineering has been explored to address intricate challenges in the field. These systems leverage the collaborative potential of multiple LLMs to enhance software development processes, including code synthesis, debugging, and project management. By distributing tasks among specialized agents, these systems aim to improve efficiency and accuracy in software engineering tasks, though further empirical studies are necessary to validate their effectiveness in real-world scenarios. \\ue200cite\\ue202turn0search6\\ue201\\n\\n**Challenges and Future Directions**\\n\\nDespite the promising advancements, several challenges persist in the development of LLM-based multi-agent systems. Ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication remain critical areas for improvement. Future research is poised to focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs in complex problem-solving contexts.\\n\\nIn summary, the integration of LLMs into multi-agent systems represents a burgeoning field with the potential to revolutionize collaborative artificial intelligence. Ongoing research continues to address existing challenges, paving the way for more sophisticated and effective multi-agent collaborations in various domains. \\n', type='ToolCallSummaryMessage'), UserInputRequestedEvent(source='user_proxy', models_usage=None, request_id='e2af9a7e-7ee0-4cba-8d0f-d5af1d426e8f', content='', type='UserInputRequestedEvent'), TextMessage(source='user_proxy', models_usage=None, content='make it shorter ', type='TextMessage'), TextMessage(source='RefinementAgent', models_usage=RequestUsage(prompt_tokens=1220, completion_tokens=219), content='**Integration of Large Language Models in Multi-Agent Systems**\\n\\nRecent advancements have focused on enhancing collaborative problem-solving and dynamic interaction capabilities in multi-agent systems through the integration of Large Language Models (LLMs). This literature review highlights key developments in system architectures, communication strategies, and application areas.\\n\\n**Key Developments**\\n\\n* The \"Chain-of-Agents\" framework enables multiple LLMs to collaborate on long-context tasks, demonstrating superior performance over traditional models.\\n* \"LongAgent\" scales LLMs to a 128K context through multi-agent collaboration, outperforming models like GPT-4 in tasks such as long-text retrieval and multi-hop question answering.\\n* The \"LLMArena\" framework assesses LLMs in dynamic multi-agent environments, revealing challenges in opponent modeling and team collaboration.\\n\\n**Challenges and Future Directions**\\n\\nDespite advancements, challenges persist, including ensuring logical consistency, managing hallucinations, and enhancing inter-agent communication. Future research will focus on refining these aspects, developing robust evaluation frameworks, and exploring diverse application domains to fully harness the potential of collaborative LLMs.', type='TextMessage')], stop_reason='Maximum number of messages 5 reached, current message count: 5')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2uC9VqY57Xx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}